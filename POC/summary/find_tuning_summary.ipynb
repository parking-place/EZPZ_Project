{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gyeonmunju/Desktop/PlayData/도서자료 요약\n"
     ]
    }
   ],
   "source": [
    "# 현재 경로 확인하기.\n",
    "dir_path = os.getcwd()\n",
    "print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "      <td>한국은「공공데이터 제공 및 이용 활성화에 관한 법률」를 만들어 공공데이터를 개방하려...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "      <td>싱가포르는 수요, 도입선 다변화, 아시아 가스 중심축으로서의 고정을 염두해 LNG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "      <td>이 사건 토지의 등기는 본점과 일산지점 모두에 관계되어 취득한 것이므로 중과대상은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "      <td>졸업유예가 증가하고 있는 상황에서 대학의 역할이 중요하다. 졸업유예 학생에 대한 관...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "      <td>고용노동부의 직업능력개발기본계획의 재원은 사용자와 근로자로부터 마련되는 것으로 노동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>학생 과정변인의 경우 선행 연구의 연구자가 활용한 설문 자료가 다양하나, 김양분․임...</td>\n",
       "      <td>학생 과정변인을 살펴보면 김양분․임현정(2010)의 연구에서는 행동통제, 학습전략,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>시민을 위한 안전을 제공하는 사회란 전쟁과 질병으로부터만 아니라 일을 통해 생계를 ...</td>\n",
       "      <td>사회보장은 기본소득을 제공하는 역할을 하기에 노동자 뿐만 아니라 가족과 지역사회에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>본 연구의 분석모형은 &lt;그림 2&gt;와 같이 크게 성과감사의 ① 환경요소, ② 기획요소...</td>\n",
       "      <td>성과감사의 바람직한 운영을 위한 '감사원'의 체계적인 '성과감사활동' 단계를 따르면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>영국 모기지 회사 핼리팩스(Halifax)에 따르면 영국 주택가격이 전월대비로 작년...</td>\n",
       "      <td>영국 주택가격 상승 폭이 확대됐고, 평균 주택가격이 193,130파운드로 2008년...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006년부터 세계경제포럼(WEF)이 경제참여와 기회, 교육적 성취, 건강과 생존,...</td>\n",
       "      <td>2006년부터 세계경제포럼이  발표해온 성격차지수에서 우리나라는 2013년 전체 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>또한 증세 동의 변수의 효과가 부적으로 바뀐 점은 무상교육에 대해 동의하는 집단이 ...</td>\n",
       "      <td>무상교육 동의 집단을 분석한 결과, 사회경제적 지위가 낮을수록 증세에 부정적이며 강...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>지연안건목록 작성 기준일은 원칙적으로 선정한 안건의 납품월의 말일로 규정하고 있다....</td>\n",
       "      <td>지연안건목록 작성 기준일은 안건 납품월의 말일로 규정하고 기준일을 초과하면 매달 초...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8학년과 9학년에서도 이 넓은 범위의 교과들이 계속되며 몇몇 학생들은 제2외국어를 ...</td>\n",
       "      <td>9학년의 학생들은 10학년, 11학년에서의 GCSE 시험 과목 선택에 대한 안내를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>응답자들의 성별에 따른 인식 차이를 비교하여 본 결과, 남녀 모두 청소년 음란물에 ...</td>\n",
       "      <td>남성은 아동음란물을 엄격히 처벌해야 한다고 했으나 여성의 경우 아동 및 청소년 음란...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>위 세 가지 방식에서 보듯이, 원스톱 샵을 위하여 국가가 통합기관을 창설할 필요는 ...</td>\n",
       "      <td>소규모 기업들은 각각의 기업들만의 독자성을 가지고 그들만의 인터페이스를 운영하는 것...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>무엇보다 향후 남북한 통합 시 “사람 간의 통합”이라는 정서적, 인식적 통합이 우선...</td>\n",
       "      <td>북한이탈주민의 군복무 제한은 휴전상황을 고려한 것이라 해도 사람 간의 통합을 막음으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“현재 주로 하는 일자리에서 하고 계시는 일이 본인의 교육수준이나 기술(기능)수준과...</td>\n",
       "      <td>교육 기술 수준 적합도가 직무의 만족에 끼치는 영향을 분석한 연구로 고령근로자를 대...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>플랫폼 노동자의 지위를 근로자로 인정해야 하는지 아니면 노무제공자로 인정해야 하는지...</td>\n",
       "      <td>플랫폼 노동자 지위 문제는 개별 크라우드 워커 사용자 규명 문제로 이어진 바, 영국...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>그렇다면 지식재산권에서 규제는 어떤 의미를 가지는 것일까? 사회과학분야 다수의 학자...</td>\n",
       "      <td>사회가 발전하려면 민간의사결정자들의 경제활동 자유가 최대한 보장되어야 한다. 이를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>삼성전자는 “미래에는 빅데이터가 모든 판단의 기준이 될 것이다”라는 것을 강조하며,...</td>\n",
       "      <td>삼성전자는 최근 거대 IT업계들과 어깨를 나란히 하기 위하여 자체적인 빅데이터 시스...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              passage  \\\n",
       "0   한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...   \n",
       "1   싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...   \n",
       "2   원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...   \n",
       "3   한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...   \n",
       "4   고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...   \n",
       "5   학생 과정변인의 경우 선행 연구의 연구자가 활용한 설문 자료가 다양하나, 김양분․임...   \n",
       "6   시민을 위한 안전을 제공하는 사회란 전쟁과 질병으로부터만 아니라 일을 통해 생계를 ...   \n",
       "7   본 연구의 분석모형은 <그림 2>와 같이 크게 성과감사의 ① 환경요소, ② 기획요소...   \n",
       "8   영국 모기지 회사 핼리팩스(Halifax)에 따르면 영국 주택가격이 전월대비로 작년...   \n",
       "9   2006년부터 세계경제포럼(WEF)이 경제참여와 기회, 교육적 성취, 건강과 생존,...   \n",
       "10  또한 증세 동의 변수의 효과가 부적으로 바뀐 점은 무상교육에 대해 동의하는 집단이 ...   \n",
       "11  지연안건목록 작성 기준일은 원칙적으로 선정한 안건의 납품월의 말일로 규정하고 있다....   \n",
       "12  8학년과 9학년에서도 이 넓은 범위의 교과들이 계속되며 몇몇 학생들은 제2외국어를 ...   \n",
       "13  응답자들의 성별에 따른 인식 차이를 비교하여 본 결과, 남녀 모두 청소년 음란물에 ...   \n",
       "14  위 세 가지 방식에서 보듯이, 원스톱 샵을 위하여 국가가 통합기관을 창설할 필요는 ...   \n",
       "15  무엇보다 향후 남북한 통합 시 “사람 간의 통합”이라는 정서적, 인식적 통합이 우선...   \n",
       "16  “현재 주로 하는 일자리에서 하고 계시는 일이 본인의 교육수준이나 기술(기능)수준과...   \n",
       "17  플랫폼 노동자의 지위를 근로자로 인정해야 하는지 아니면 노무제공자로 인정해야 하는지...   \n",
       "18  그렇다면 지식재산권에서 규제는 어떤 의미를 가지는 것일까? 사회과학분야 다수의 학자...   \n",
       "19  삼성전자는 “미래에는 빅데이터가 모든 판단의 기준이 될 것이다”라는 것을 강조하며,...   \n",
       "\n",
       "                                              summary  \n",
       "0   한국은「공공데이터 제공 및 이용 활성화에 관한 법률」를 만들어 공공데이터를 개방하려...  \n",
       "1   싱가포르는 수요, 도입선 다변화, 아시아 가스 중심축으로서의 고정을 염두해 LNG ...  \n",
       "2   이 사건 토지의 등기는 본점과 일산지점 모두에 관계되어 취득한 것이므로 중과대상은 ...  \n",
       "3   졸업유예가 증가하고 있는 상황에서 대학의 역할이 중요하다. 졸업유예 학생에 대한 관...  \n",
       "4   고용노동부의 직업능력개발기본계획의 재원은 사용자와 근로자로부터 마련되는 것으로 노동...  \n",
       "5   학생 과정변인을 살펴보면 김양분․임현정(2010)의 연구에서는 행동통제, 학습전략,...  \n",
       "6   사회보장은 기본소득을 제공하는 역할을 하기에 노동자 뿐만 아니라 가족과 지역사회에 ...  \n",
       "7   성과감사의 바람직한 운영을 위한 '감사원'의 체계적인 '성과감사활동' 단계를 따르면...  \n",
       "8   영국 주택가격 상승 폭이 확대됐고, 평균 주택가격이 193,130파운드로 2008년...  \n",
       "9   2006년부터 세계경제포럼이  발표해온 성격차지수에서 우리나라는 2013년 전체 1...  \n",
       "10  무상교육 동의 집단을 분석한 결과, 사회경제적 지위가 낮을수록 증세에 부정적이며 강...  \n",
       "11  지연안건목록 작성 기준일은 안건 납품월의 말일로 규정하고 기준일을 초과하면 매달 초...  \n",
       "12  9학년의 학생들은 10학년, 11학년에서의 GCSE 시험 과목 선택에 대한 안내를 ...  \n",
       "13  남성은 아동음란물을 엄격히 처벌해야 한다고 했으나 여성의 경우 아동 및 청소년 음란...  \n",
       "14  소규모 기업들은 각각의 기업들만의 독자성을 가지고 그들만의 인터페이스를 운영하는 것...  \n",
       "15  북한이탈주민의 군복무 제한은 휴전상황을 고려한 것이라 해도 사람 간의 통합을 막음으...  \n",
       "16  교육 기술 수준 적합도가 직무의 만족에 끼치는 영향을 분석한 연구로 고령근로자를 대...  \n",
       "17  플랫폼 노동자 지위 문제는 개별 크라우드 워커 사용자 규명 문제로 이어진 바, 영국...  \n",
       "18  사회가 발전하려면 민간의사결정자들의 경제활동 자유가 최대한 보장되어야 한다. 이를 ...  \n",
       "19  삼성전자는 최근 거대 IT업계들과 어깨를 나란히 하기 위하여 자체적인 빅데이터 시스...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 불러오기.\n",
    "df= pd.read_csv(\"./사회과학_passage_summary.csv\")\n",
    "\n",
    "# 데이터가 너무 많아서 100개로 줄였습니다.\n",
    "df = df.head(20)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mT5_m2m_crossSum_enhanced 모델 가져오기. (tokenizer, model)\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# GPU 연산 중에 특정 버그나 호환성 문제가 발생할 수 있기 때문에 use_fast=False를 사용한다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/mT5_m2m_crossSum_enhanced\", use_fast=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/mT5_m2m_crossSum_enhanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 class 불러오기.\n",
    "from mt5sum import MT5Sum\n",
    "review_summary = MT5Sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>학생 과정변인의 경우 선행 연구의 연구자가 활용한 설문 자료가 다양하나, 김양분․임...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>시민을 위한 안전을 제공하는 사회란 전쟁과 질병으로부터만 아니라 일을 통해 생계를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>본 연구의 분석모형은 &lt;그림 2&gt;와 같이 크게 성과감사의 ① 환경요소, ② 기획요소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>영국 모기지 회사 핼리팩스(Halifax)에 따르면 영국 주택가격이 전월대비로 작년...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006년부터 세계경제포럼(WEF)이 경제참여와 기회, 교육적 성취, 건강과 생존,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>또한 증세 동의 변수의 효과가 부적으로 바뀐 점은 무상교육에 대해 동의하는 집단이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>지연안건목록 작성 기준일은 원칙적으로 선정한 안건의 납품월의 말일로 규정하고 있다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8학년과 9학년에서도 이 넓은 범위의 교과들이 계속되며 몇몇 학생들은 제2외국어를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>응답자들의 성별에 따른 인식 차이를 비교하여 본 결과, 남녀 모두 청소년 음란물에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>위 세 가지 방식에서 보듯이, 원스톱 샵을 위하여 국가가 통합기관을 창설할 필요는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>무엇보다 향후 남북한 통합 시 “사람 간의 통합”이라는 정서적, 인식적 통합이 우선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“현재 주로 하는 일자리에서 하고 계시는 일이 본인의 교육수준이나 기술(기능)수준과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>플랫폼 노동자의 지위를 근로자로 인정해야 하는지 아니면 노무제공자로 인정해야 하는지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>그렇다면 지식재산권에서 규제는 어떤 의미를 가지는 것일까? 사회과학분야 다수의 학자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>삼성전자는 “미래에는 빅데이터가 모든 판단의 기준이 될 것이다”라는 것을 강조하며,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              passage\n",
       "0   한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...\n",
       "1   싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...\n",
       "2   원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...\n",
       "3   한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...\n",
       "4   고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...\n",
       "5   학생 과정변인의 경우 선행 연구의 연구자가 활용한 설문 자료가 다양하나, 김양분․임...\n",
       "6   시민을 위한 안전을 제공하는 사회란 전쟁과 질병으로부터만 아니라 일을 통해 생계를 ...\n",
       "7   본 연구의 분석모형은 <그림 2>와 같이 크게 성과감사의 ① 환경요소, ② 기획요소...\n",
       "8   영국 모기지 회사 핼리팩스(Halifax)에 따르면 영국 주택가격이 전월대비로 작년...\n",
       "9   2006년부터 세계경제포럼(WEF)이 경제참여와 기회, 교육적 성취, 건강과 생존,...\n",
       "10  또한 증세 동의 변수의 효과가 부적으로 바뀐 점은 무상교육에 대해 동의하는 집단이 ...\n",
       "11  지연안건목록 작성 기준일은 원칙적으로 선정한 안건의 납품월의 말일로 규정하고 있다....\n",
       "12  8학년과 9학년에서도 이 넓은 범위의 교과들이 계속되며 몇몇 학생들은 제2외국어를 ...\n",
       "13  응답자들의 성별에 따른 인식 차이를 비교하여 본 결과, 남녀 모두 청소년 음란물에 ...\n",
       "14  위 세 가지 방식에서 보듯이, 원스톱 샵을 위하여 국가가 통합기관을 창설할 필요는 ...\n",
       "15  무엇보다 향후 남북한 통합 시 “사람 간의 통합”이라는 정서적, 인식적 통합이 우선...\n",
       "16  “현재 주로 하는 일자리에서 하고 계시는 일이 본인의 교육수준이나 기술(기능)수준과...\n",
       "17  플랫폼 노동자의 지위를 근로자로 인정해야 하는지 아니면 노무제공자로 인정해야 하는지...\n",
       "18  그렇다면 지식재산권에서 규제는 어떤 의미를 가지는 것일까? 사회과학분야 다수의 학자...\n",
       "19  삼성전자는 “미래에는 빅데이터가 모든 판단의 기준이 될 것이다”라는 것을 강조하며,..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 존재했던 요약본을 없앤 데이터셋.\n",
    "passage_df = df.drop('summary',axis=1)\n",
    "passage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "      <td>한국은 세계 최대 공공데이터 개방 국가 중 1위에 올랐다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "      <td>싱가포르가 세계 최대 규모의 원유시설 중 하나로 선정됐다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "      <td>원심이 지난 2일 오전 9시(현지시간) 신종 코로나바이러스 감염증과 사태에 대한 조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "      <td>중국에서 졸업유예가 1년 만에 최저 수치를 받았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "      <td>고용노동부의 직업능력개발 기본 계획이 발표됐다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             passage  \\\n",
       "0  한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...   \n",
       "1  싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...   \n",
       "2  원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...   \n",
       "3  한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...   \n",
       "4  고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...   \n",
       "\n",
       "                                             summary  \n",
       "0                   한국은 세계 최대 공공데이터 개방 국가 중 1위에 올랐다.  \n",
       "1                   싱가포르가 세계 최대 규모의 원유시설 중 하나로 선정됐다.  \n",
       "2  원심이 지난 2일 오전 9시(현지시간) 신종 코로나바이러스 감염증과 사태에 대한 조...  \n",
       "3                       중국에서 졸업유예가 1년 만에 최저 수치를 받았다.  \n",
       "4                         고용노동부의 직업능력개발 기본 계획이 발표됐다.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 이용하여 요약본을 만들고, 데이터셋을 원본과 요약본을 합쳤다.\n",
    "# (학습데이터:passage, 정답데이터:summary)\n",
    "passage_df['summary'] = passage_df[\"passage\"].apply(review_summary.get_sum)\n",
    "passage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device 정하기. (cpu)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터와 정답데이터 생성\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(passage_df[\"passage\"],\n",
    "                                                  passage_df[\"summary\"],\n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582401280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 파라미터 값\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 768)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 프로세스 - 데이터 불러오기\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Doc2SumData(Dataset):\n",
    "  # 초기화 하는 함수 init\n",
    "  def __init__(self, data, tokenizer, max_input_len=512, max_output_len=64):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.max_input_len = max_input_len\n",
    "    self.max_output_len = max_output_len\n",
    "\n",
    "  # \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  # \n",
    "  def __getitem__(self, index):\n",
    "    input_text = self.data[index]['passage']\n",
    "    summary_text = self.data[index]['summary']\n",
    "    input_ids = torch.tensor(self.tokenizer.encode(input_text)[:self.max_input_len])\n",
    "    attention_mask = torch.tensor([1] * len(input_ids))\n",
    "    output_ids = torch.tensor(self.tokenizer.encode(summary_text)[:self.max_output_len])\n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'decoder_input_ids': output_ids[:-1],\n",
    "            'decoder_attention_mask': torch.tensor([1] * (len(output_ids)-1)),\n",
    "            'decoder_target_ids': output_ids[1:]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝 프로세스 - 모델 및 프로세스 정의\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gyeonmunju/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer 준비\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_dataset = Doc2SumData(passage_df, tokenizer,max_input_len=512, max_output_len=64)\n",
    "\n",
    "# Dataloader 생성\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=2, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = T5ForConditionalGeneration.from_pretrained('csebuetnlp/mT5_m2m_crossSum_enhanced').to(device)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "epochs = 3\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Optimizer 및 Scheduler 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=epochs)\n",
    "\n",
    "# Loss 함수 설정\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x2ae8541f0>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m# 파인튜닝 실행\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mfor\u001b[39;00m idx, batch \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39;49m(train_loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_loader)):\n\u001b[1;32m     25\u001b[0m         loss \u001b[39m=\u001b[39m train_on_batch(model, optimizer, batch, criterion)\n\u001b[1;32m     26\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m02d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Batch: \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages/torch/utils/data/dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1035\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1044\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, fp)\n\u001b[1;32m     48\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.11/lib/python3.10/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x2ae8541f0>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "# 학습 프로세스 정의\n",
    "def train_on_batch(model, optimizer, batch, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    decoder_input_ids = batch['decoder_input_ids'].to(device)\n",
    "    decoder_attention_mask = batch['decoder_attention_mask'].to(device)\n",
    "    decoder_target_ids = batch['decoder_target_ids'].to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                    decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask,\n",
    "                    use_cache=False)\n",
    "\n",
    "    loss = criterion(outputs[0].view(-1, outputs[0].shape[2]), decoder_target_ids.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# 파인튜닝 실행\n",
    "for epoch in range(epochs):\n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        loss = train_on_batch(model, optimizer, batch, criterion)\n",
    "        print(f'Epoch: {epoch+1:02d} | Batch: {idx+1:03d} | Loss: {loss:.4f}')\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 파인튜닝 모델\n",
    "\n",
    "class Data(Dataset):\n",
    "\n",
    "    # 초기화하는게 init함수.\n",
    "    def __init__(self, data, tokenizer, max_output_len=128):\n",
    "\n",
    "        # 부모인 class를 가져오는게 super함수.\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_output_len = max_output_len\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        # 모델을 model_name으로 객체를 만들어줌.\n",
    "        model_name = \"csebuetnlp/mT5_m2m_crossSum_enhanced\"\n",
    "        \n",
    "        # 토크나이져 해야하는데...\n",
    "        self.__tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # 모델을 분류는 좀 더 찾아봐야함.\n",
    "        self.__model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        # 모델의 Device는 cpu로 일단 돌리도록하겠슴다.\n",
    "        self.__model.to(device)\n",
    "\n",
    "    # forward 함수는 입력 tensor로부터 출력 tensor를 계산하는 함수.\n",
    "    def forward(self, original): #여기서 text를 받아 토큰화 시키고 output을 받으며 probs로 비선형화후 제일높은 확률의 친구를 pred에 넣어서 반환\n",
    "        # 원본을 받아와서 output으로 요약본을 보내야한다.\n",
    "        #x = self.model(**x)\n",
    "        #x = self.output_layer(x[1])\n",
    "        #inputs = self.__tokenizer(text, return_tensors='pt').to(DEVICE) 이미 토큰화돼있으므로\n",
    "        #outputs = self.__model(**inputs)\n",
    "        outputs= self.__model(**original) #토큰화된 text의 key들을 모델에 넘겨줌\n",
    "        probs=outputs.logits\n",
    "        print(probs)\n",
    "        #probs = self.__softmax(outputs.logits, dim=1) #output logit의 3개의 값을 활성화함수에 넣어줌\n",
    "        print(probs.argmax().item())\n",
    "        print(self.__model.config.id2label)\n",
    "        #pred = self.__model.config.id2label[probs.argmax().item()].keys() #id2label 은 답이 담겨있는 dict 0:negative 1:neutral 2:positive\n",
    "        pred=probs.argmax().item() #요거 써야됨\n",
    "        #pred=torch.tensor(pred) 요거 써야됨\n",
    "        pred=torch.tensor(pred).reshape(1,1)\n",
    "        #따라서 배치사이즈 1로 해서 한번 할 때마다 3개 중에 하나 고르게 하기 또한 pred에는 positive(str)이 저장되므로 value로 바꿔줌\n",
    "        #잠깐 어차피 확률 3개중 제일 높은게 item이라면 계속 넣어주면되는거 아님\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /Users/gyeonmunju/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages (from nltk) (1.3.1)\n",
      "Collecting click\n",
      "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/gyeonmunju/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/gyeonmunju/.pyenv/versions/3.10.11/envs/ezpz/lib/python3.10/site-packages (from nltk) (2023.6.3)\n",
      "Installing collected packages: click, nltk\n",
      "Successfully installed click-8.1.6 nltk-3.8.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "      <td>한국은「공공데이터 제공 및 이용 활성화에 관한 법률」를 만들어 공공데이터를 개방하려...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "      <td>싱가포르는 수요, 도입선 다변화, 아시아 가스 중심축으로서의 고정을 염두해 LNG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "      <td>이 사건 토지의 등기는 본점과 일산지점 모두에 관계되어 취득한 것이므로 중과대상은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "      <td>졸업유예가 증가하고 있는 상황에서 대학의 역할이 중요하다. 졸업유예 학생에 대한 관...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "      <td>고용노동부의 직업능력개발기본계획의 재원은 사용자와 근로자로부터 마련되는 것으로 노동...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             passage  \\\n",
       "0  한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...   \n",
       "1  싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...   \n",
       "2  원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...   \n",
       "3  한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...   \n",
       "4  고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...   \n",
       "\n",
       "                                             summary  \n",
       "0  한국은「공공데이터 제공 및 이용 활성화에 관한 법률」를 만들어 공공데이터를 개방하려...  \n",
       "1  싱가포르는 수요, 도입선 다변화, 아시아 가스 중심축으로서의 고정을 염두해 LNG ...  \n",
       "2  이 사건 토지의 등기는 본점과 일산지점 모두에 관계되어 취득한 것이므로 중과대상은 ...  \n",
       "3  졸업유예가 증가하고 있는 상황에서 대학의 역할이 중요하다. 졸업유예 학생에 대한 관...  \n",
       "4  고용노동부의 직업능력개발기본계획의 재원은 사용자와 근로자로부터 마련되는 것으로 노동...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 불러오기.\n",
    "t5_df= pd.read_csv(\"./사회과학_passage_summary.csv\")\n",
    "t5_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5-small-korean-summarization 모델 가져오기. (tokenizer, model)\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"eenzeenee/t5-small-korean-summarization\")\n",
    "t5_model = AutoModelForSeq2SeqLM.from_pretrained(\"eenzeenee/t5-small-korean-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gyeonmunju/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 모델의 class 불러오기.\n",
    "from m5basesum import T5BaseSum\n",
    "t5_review_summary = T5BaseSum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115435</th>\n",
       "      <td>교육부(장관 황우여)와 인성교육범국민실천연합(상임대표 안양옥, 이하 인실련)은 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115436</th>\n",
       "      <td>한반도에 항구적 평화를 정착시키기 위해서는 우선 우리 민족의 생명과 안전은 물론 국...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115437</th>\n",
       "      <td>문자 체계는 크게 표의 문자(중국어)와 표음 문자로 나눌 수 있고, 표음 문자는 다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115438</th>\n",
       "      <td>양 장관은 3자 또는 다자 협력을 통한 평화유지활동, 안정화 및 재건 지원, 인도적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115439</th>\n",
       "      <td>다섯째, 먼저 생활의 정리정돈부터 연습하는 것이 효과적이다. 특히, 초등학교 3학년...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115440 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  passage\n",
       "0       한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...\n",
       "1       싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...\n",
       "2       원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...\n",
       "3       한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...\n",
       "4       고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...\n",
       "...                                                   ...\n",
       "115435  교육부(장관 황우여)와 인성교육범국민실천연합(상임대표 안양옥, 이하 인실련)은 10...\n",
       "115436  한반도에 항구적 평화를 정착시키기 위해서는 우선 우리 민족의 생명과 안전은 물론 국...\n",
       "115437  문자 체계는 크게 표의 문자(중국어)와 표음 문자로 나눌 수 있고, 표음 문자는 다...\n",
       "115438  양 장관은 3자 또는 다자 협력을 통한 평화유지활동, 안정화 및 재건 지원, 인도적...\n",
       "115439  다섯째, 먼저 생활의 정리정돈부터 연습하는 것이 효과적이다. 특히, 초등학교 3학년...\n",
       "\n",
       "[115440 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 존재했던 요약본을 없앤 데이터셋.\n",
    "t5_passage_df = t5_df.drop('summary',axis=1)\n",
    "t5_passage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             passage\n",
       "0  한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...\n",
       "1  싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...\n",
       "2  원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...\n",
       "3  한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...\n",
       "4  고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 115440개의 데이터가 너무 오래걸리기에 5개만 넣었습니다.\n",
    "t5_passage_df_temp = t5_passage_df[:5]\n",
    "t5_passage_df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...</td>\n",
       "      <td>한국은 2013년 OECD 공공데이터 개방 평가에서 1위를 차지했고 현재 한국의 데...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...</td>\n",
       "      <td>싱가포르는 국내 천연가스 수요 충족 및 도입선 다변화 등을 염두에 두고 LNG 수입...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...</td>\n",
       "      <td>원심은 이 사건 토지의 등기는 일산지점을 기준으로 할 경우 원고 법인이 지점 설치 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...</td>\n",
       "      <td>중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 대학의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...</td>\n",
       "      <td>고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 노동조합이 참...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             passage  \\\n",
       "0  한국은 2013년 「공공데이터 제공 및 이용 활성화에 관한 법률」을 제정한 이후 공...   \n",
       "1  싱가포르는 늘어나는 국내 천연가스 수요 충족, 도입선 다변화, 아시아 가스 허브로서...   \n",
       "2  원심은 같은 취지에서, 이 사건 토지의 등기는 일산지점을 기준으로 할 경우에는 원고...   \n",
       "3  한편, 중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 ...   \n",
       "4  고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 우리 사회의 ...   \n",
       "\n",
       "                                             summary  \n",
       "0  한국은 2013년 OECD 공공데이터 개방 평가에서 1위를 차지했고 현재 한국의 데...  \n",
       "1  싱가포르는 국내 천연가스 수요 충족 및 도입선 다변화 등을 염두에 두고 LNG 수입...  \n",
       "2  원심은 이 사건 토지의 등기는 일산지점을 기준으로 할 경우 원고 법인이 지점 설치 ...  \n",
       "3  중국의 고등교육 전문가들은 졸업유예가 증가하고 있는 상황에서 이에 대응하는 대학의 ...  \n",
       "4  고용노동부의 직업능력개발기본계획은 고용보험 직업능력개발사업을 중심으로 노동조합이 참...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 이용하여 요약본을 만들고, 데이터셋을 원본과 요약본을 합쳤다.\n",
    "t5_passage_df['summary'] = t5_passage_df_temp[\"passage\"].apply(t5_review_summary.get_sum)\n",
    "t5_passage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezpz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
