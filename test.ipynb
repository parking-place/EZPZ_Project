{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"csebuetnlp/mT5_m2m_crossSum_enhanced\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "MT5ForConditionalGeneration                                  --\n",
       "├─Embedding: 1-1                                             192,086,016\n",
       "├─MT5Stack: 1-2                                              192,086,016\n",
       "│    └─Embedding: 2-1                                        (recursive)\n",
       "│    └─ModuleList: 2-2                                       --\n",
       "│    │    └─MT5Block: 3-1                                    7,079,808\n",
       "│    │    └─MT5Block: 3-2                                    7,079,424\n",
       "│    │    └─MT5Block: 3-3                                    7,079,424\n",
       "│    │    └─MT5Block: 3-4                                    7,079,424\n",
       "│    │    └─MT5Block: 3-5                                    7,079,424\n",
       "│    │    └─MT5Block: 3-6                                    7,079,424\n",
       "│    │    └─MT5Block: 3-7                                    7,079,424\n",
       "│    │    └─MT5Block: 3-8                                    7,079,424\n",
       "│    │    └─MT5Block: 3-9                                    7,079,424\n",
       "│    │    └─MT5Block: 3-10                                   7,079,424\n",
       "│    │    └─MT5Block: 3-11                                   7,079,424\n",
       "│    │    └─MT5Block: 3-12                                   7,079,424\n",
       "│    └─MT5LayerNorm: 2-3                                     768\n",
       "│    └─Dropout: 2-4                                          --\n",
       "├─MT5Stack: 1-3                                              192,086,016\n",
       "│    └─Embedding: 2-5                                        (recursive)\n",
       "│    └─ModuleList: 2-6                                       --\n",
       "│    │    └─MT5Block: 3-13                                   9,439,872\n",
       "│    │    └─MT5Block: 3-14                                   9,439,488\n",
       "│    │    └─MT5Block: 3-15                                   9,439,488\n",
       "│    │    └─MT5Block: 3-16                                   9,439,488\n",
       "│    │    └─MT5Block: 3-17                                   9,439,488\n",
       "│    │    └─MT5Block: 3-18                                   9,439,488\n",
       "│    │    └─MT5Block: 3-19                                   9,439,488\n",
       "│    │    └─MT5Block: 3-20                                   9,439,488\n",
       "│    │    └─MT5Block: 3-21                                   9,439,488\n",
       "│    │    └─MT5Block: 3-22                                   9,439,488\n",
       "│    │    └─MT5Block: 3-23                                   9,439,488\n",
       "│    │    └─MT5Block: 3-24                                   9,439,488\n",
       "│    └─MT5LayerNorm: 2-7                                     768\n",
       "│    └─Dropout: 2-8                                          --\n",
       "├─Linear: 1-4                                                192,086,016\n",
       "=====================================================================================\n",
       "Total params: 966,573,312\n",
       "Trainable params: 966,573,312\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = r'''\n",
    "연차사용이 자유롭고 분위기가 느슨하다. 유연근무제 도입했다.\n",
    "연봉은 최악이며 미래먹거리가 없으며 저마다 처신하기 바쁨.\n",
    "제발 정신좀차리고 주인의식 좀 느끼세요. 그대들 배부르다고 직원들도 배부른줄아나?\n",
    "자유로운 연차 사용으로 원할때 사용하면 되며, 직원들을 위해서 다양한 소통 문화를 만들려고 함.\n",
    "개인 연차나 비활동시에도 시스템에서 바로 확인되었으면 좋겠고, 연차 시 확인이 안되서 업무 전화가 많이 옴.\n",
    "회사 직원들의 의견을 더 들어주셨으면 좋겠고, 적극적으로 반영해주셨으면 좋겠습니다.\n",
    "월급 안밀리고 밥나오고 연차를 눈치없이 쓸 수 있음.\n",
    "오래다니면 다닐수록 일이 더 쉬워짐.\n",
    "직원을 홀대하고 연봉을 올려주지 않는 반면 경력직들은 직전연봉 다 챙겨줘 가며 입사시킴.\n",
    "바라는 것도 없고 그냔 이대로만 해주세요. 잘하고 있다면서요?\n",
    "연차 자율제도와 유연근무 제도로 가정에 더 충실할 수 있고 삶이 생긴다.\n",
    "한량? 들이 많고 일을 하려는 의지들이 약하며 다들 불만만 많은 상황인데 인사정책은 더 역효과를 불러옴.\n",
    "본인들 평가나 성과를 위한 업무를 하지말고 밑에 사람들을 돌보아야 될듯.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = article_text.replace('\\n', ' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'device': 'cuda'} not recognized.\n"
     ]
    }
   ],
   "source": [
    "get_lang_id = lambda lang: tokenizer._convert_token_to_id(\n",
    "    model.config.task_specific_params[\"langid_map\"][lang][1]\n",
    ") \n",
    "\n",
    "target_lang = \"korean\" # for a list of available language names see below\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [WHITESPACE_HANDLER(article_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    ")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda\")\n",
    "input_ids = input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    decoder_start_token_id=get_lang_id(target_lang),\n",
    "    max_length=84,\n",
    "    no_repeat_ngram_size=1,\n",
    "    num_beams=4,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tokenizer.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_70> 회사에서 연차 사용이 자유롭고 분위기가 느슨하다.\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sae4k_df(path='/home/parking/ml/data/MiniProj/data/sae4k/sae4k_v2.txt'):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sae4KDataset(Dataset):\n",
    "    def __init__(self, tokenizer, df):\n",
    "        self.__tokenizer = tokenizer\n",
    "        self.__df = df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ezpz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
